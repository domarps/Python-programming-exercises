{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A no-nonsense guide to generators!!\n",
    "\n",
    "Adapted from: Three Keys to Leveling Up your Python by Aaron Maxwell (aaron@powerfulpython.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make your Python code scalable\n",
    "\n",
    "```python\n",
    "def fetch_squares(max_root):\n",
    "    squares = []\n",
    "    for x in range(max_root):\n",
    "        squares.append(x**2)\n",
    "    return squares\n",
    "MAX = 5\n",
    "for square in fetch_squares(MAX):\n",
    "    do_something_with(square)\n",
    "```\n",
    "The following code causes:\n",
    "- `fetch_squares` creates an **entire list** in memory\n",
    "-  As `MAX` increases, the program is forced to page to disk (and therefore becomes sluggish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16]\n"
     ]
    }
   ],
   "source": [
    "def gen_squares(max_root):\n",
    "    for x in range(max_root):\n",
    "        yield x**2\n",
    "squares = gen_squares(5)\n",
    "print([sq for sq in squares])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### key points of generator function:\n",
    "- A function is a generator function if and only if it contains the `yield` keyword\n",
    "- A generator function returns a generator object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(squares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notes about generators:\n",
    "- The scalability benefit of the generator object is like a raw iterator\n",
    "- every generator object is an iterator but not the other way around\n",
    "- easiest way to create an iterator is the generator object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next() thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 4 9 16\n",
      "thats all folks\n"
     ]
    }
   ],
   "source": [
    "squares = gen_squares(5)\n",
    "print(next(squares), next(squares), next(squares), next(squares), next(squares))\n",
    "# next lets you supply the default value, in this case : None\n",
    "if next(squares, None) == None: \n",
    "    print('thats all folks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_up_to(limit):\n",
    "    n = 0\n",
    "    while n <= limit:\n",
    "        yield n\n",
    "        n += 1\n",
    "limit = 10\n",
    "it = gen_up_to(limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(it, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use case 1 : `pattern matching` log files with `small memory footprint`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def matching_lines(pattern, path):\n",
    "    '''\n",
    "    generator function matches lines from a log file based on pattern\n",
    "    :param path : file with records one per line\n",
    "    :return yields an object\n",
    "    '''\n",
    "    with open(path) as handler_list:\n",
    "        for line in handler_list:\n",
    "            if pattern in line:\n",
    "                yield line.rstrip('\\n')\n",
    "pattern, path = 'WARNING', 'log.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WARNING : Disk usage exceeding 85%', 'WARNING : Almost out of coconut water']\n"
     ]
    }
   ],
   "source": [
    "print([line for line in matching_lines(pattern, path)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use case 2 : `Transforming` log files to `dictionaries`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_log_records(lines):\n",
    "    '''\n",
    "    return a dictionary to parse log records\n",
    "    : param lines\n",
    "    : yield dict with two keys\n",
    "    '''\n",
    "    for line in lines:\n",
    "        level, message = line.split(\": \", 1)\n",
    "        yield {\"level\" : level, \"message\" : message}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'level': 'WARNING ', 'message': 'Disk usage exceeding 85%'}, {'level': 'WARNING ', 'message': 'Almost out of coconut water'}]\n"
     ]
    }
   ],
   "source": [
    "print([record for record in parse_log_records(matching_lines(pattern, path))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With the two building blocks `parse_log_records` and `matching_lines`, lets proceed to build a class `Logs`, which comes quite handy during data engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logs:\n",
    "    def __init__(self, log_file_path):\n",
    "        self.log_file_path = log_file_path\n",
    "    def records(self):\n",
    "        with open(self.log_file_path) as log_lines:\n",
    "                 for record in parse_log_records(log_lines):\n",
    "                    yield record\n",
    "    def warnings(self):\n",
    "        log_lines = matching_lines(\"WARNING\", self.log_file_path)\n",
    "        for record in parse_log_records(log_lines):\n",
    "            yield record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = Logs('log.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'level': 'WARNING ', 'message': 'Disk usage exceeding 85%\\n'}, {'level': 'DEBUG ', 'message': \"User 'tinytim' upgraded to pro\\n\"}, {'level': 'INFO ', 'message': 'Sent email campaign, completed normally\\n'}, {'level': 'WARNING ', 'message': 'Almost out of coconut water\\n'}]\n"
     ]
    }
   ],
   "source": [
    "print([record for record in logs.records()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'level': 'WARNING ', 'message': 'Disk usage exceeding 85%'}, {'level': 'WARNING ', 'message': 'Almost out of coconut water'}]\n"
     ]
    }
   ],
   "source": [
    "print([record for record in logs.warnings()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
